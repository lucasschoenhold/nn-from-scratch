{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93326dfb-3a28-49fa-98ca-585e3d892c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b503f558-d37a-4136-af1f-745861202a2d",
   "metadata": {},
   "source": [
    "# Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cd3d7c-227f-4924-b2f0-5767e3d3fb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, _children=(), _op: str = None, label: str = \"\"):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        self._backward: callable = lambda: None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        other = (\n",
    "            other if isinstance(other, Value) else Value(other)\n",
    "        )  # Supporting add of integers\n",
    "        out = Value(self.data + other.data, _children=(self, other), _op=\"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += 1.0 * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __neg__(self):\n",
    "        return self * -1\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return self + (-other)\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        other = other if isinstance(other, Value) else Value(other)\n",
    "        out = Value(self.data * other.data, _children=(self, other), _op=\"*\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __rmul__(self, other):  # int + object\n",
    "        return self.__mul__(other)\n",
    "\n",
    "    def __pow__(self, other):\n",
    "        assert isinstance(other, int | float)\n",
    "        out = Value(self.data**other, (self,), _op=f\"**{other}\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other * (self.data ** (other - 1)) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "\n",
    "        return out\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        return self * other**-1\n",
    "\n",
    "    def exp(self):\n",
    "        x = self.data\n",
    "        out = Value(math.exp(x), (self,), \"exp\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad = out.data * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2 * x) - 1) / (math.exp(2 * x) + 1)\n",
    "        out = Value(t, _children=(self,), _op=\"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - t**2) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "\n",
    "        build_topo(self)\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):  # Needs to be reversed because we start at the end\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346c751-2903-459e-aca0-405f0c0044a7",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e9c47-7a58-4527-b976-050f4c2721e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the computation graph\n",
    "from graphviz import Digraph\n",
    "\n",
    "\n",
    "def trace(root):\n",
    "    nodes, edges = set(), set()\n",
    "\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "# for any value use a rectangle, for any operation use a circle\n",
    "def draw_graph(value: Value):\n",
    "    dot = Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})  # Left to right\n",
    "    nodes, edges = trace(value)\n",
    "    # For each node, add a rectangle with the value\n",
    "    for n in nodes:\n",
    "        uid = str(id(n))\n",
    "        dot.node(\n",
    "            name=uid,\n",
    "            label=\"{%s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad),\n",
    "            shape=\"record\",\n",
    "        )\n",
    "        # For any operation, use a circle\n",
    "        if n._op:\n",
    "            dot.node(name=uid + n._op, label=n._op)\n",
    "            # Add edges to the graph\n",
    "            dot.edge(uid + n._op, uid)\n",
    "    for n1, n2 in edges:\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c044b27-411f-4613-a34d-e22739ec2ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0)\n",
    "a * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699b4995-5860-44b8-9f15-8a6652fc246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0)\n",
    "a + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c72318-d1b8-472b-81eb-3342448a8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0)\n",
    "2 * a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b30fddb-3cce-48fb-b0ee-1eaec1b8a48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(2.0)\n",
    "b = Value(4.0)\n",
    "\n",
    "a / b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809a14b-a5b4-4971-a546-fd0da45ca4dc",
   "metadata": {},
   "source": [
    "To implement division we're going to gerneralize what division means:\n",
    "\n",
    "$$\n",
    "\\frac{a}{b} = a \\cdot \\frac{1}{b} = a \\cdot b^{-1}\n",
    "$$\n",
    "\n",
    "so we're going to implement a function that can compute:\n",
    "$$\n",
    "x^k \\text{ for any x,k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b41a889-5f3a-48db-b596-e795a618fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a - b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defbe1a8-20ae-4e65-80c3-1b2a6b2cd0f5",
   "metadata": {},
   "source": [
    "# Mathematically Equivalancy\n",
    "\n",
    "You can define the operations on **any** abstraction level you please as long as it's mathematically correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e211889-d422-4550-8734-c1d8b970585b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1,x2\n",
    "x1 = Value(2.0, label=\"x1\")\n",
    "x2 = Value(0.0, label=\"x2\")\n",
    "# weights wl,w2\n",
    "w1 = Value(-3.0, label=\"w1\")\n",
    "w2 = Value(1.0, label=\"w2\")\n",
    "# bias of the neuron\n",
    "b = Value(6.8813735870195432, label=\"b\")  # Value set so the numbers come out \"nice\"\n",
    "# x1*w1 + x2*w2 + b\n",
    "x1w1 = x1 * w1\n",
    "x1w1.label = \"x1*w1\"\n",
    "x2w2 = x2 * w2\n",
    "x2w2.label = \"x2*w2\"\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "x1w1x2w2.label = \"x1*w1 + x2*w2\"\n",
    "n = x1w1x2w2 + b\n",
    "n.label = \"n\"\n",
    "o = n.tanh()\n",
    "o.label = \"o\"\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f687d11-0935-4d19-a76d-0cf1268c8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56a93a2-fe6d-461f-82a1-dce3883152cd",
   "metadata": {},
   "source": [
    "\n",
    "The following implements the same functionality as above, just instead of using $\\tanh$ directly we use one of it's representations since:\n",
    "$$\n",
    "\\tanh(x) = \\frac{e^{2n} - 1}{e^{2n} + 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360e2d53-4bae-4101-81c6-a656bf94187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1,x2\n",
    "x1 = Value(2.0, label=\"x1\")\n",
    "x2 = Value(0.0, label=\"x2\")\n",
    "# weights wl,w2\n",
    "w1 = Value(-3.0, label=\"w1\")\n",
    "w2 = Value(1.0, label=\"w2\")\n",
    "# bias of the neuron\n",
    "b = Value(6.8813735870195432, label=\"b\")  # Value set so the numbers come out \"nice\"\n",
    "# x1*w1 + x2*w2 + b\n",
    "x1w1 = x1 * w1\n",
    "x1w1.label = \"x1*w1\"\n",
    "x2w2 = x2 * w2\n",
    "x2w2.label = \"x2*w2\"\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "x1w1x2w2.label = \"x1*w1 + x2*w2\"\n",
    "n = x1w1x2w2 + b\n",
    "n.label = \"n\"\n",
    "# ---------\n",
    "e = (2 * n).exp()\n",
    "o = (e - 1) / (e + 1)\n",
    "# ---------\n",
    "o.label = \"o\"\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ab7965-2018-4cfb-a9b5-cf349fd921bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7151f65-c499-4517-b0f0-efc63c3359e9",
   "metadata": {},
   "source": [
    "and it returns the same result in terms of values of data and gradients as $\\tanh$, just with a longer computational graph as it is now more explicit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01dc751-5aa7-4e68-9990-88306d4b3c5a",
   "metadata": {},
   "source": [
    "# PyTorch Sanity Check\n",
    "We're now going to verify the result using a modern deep learning framework such as PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d601d4d8-c3c8-402e-96d0-57fe26e8ec35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994bd2a8-5907-447e-a38f-80f2fc8c8ce9",
   "metadata": {},
   "source": [
    "Because the variables are leaf nodes, PyTorch for efficiency reasons does not automatically compute the gradients, we therefore have to force it to, by setting the attributes ``requires_grad = True`` so it does backpropagation when we call ``backward()`` on the last object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cdd6f0-3653-465e-b284-496d244f8b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = torch.tensor([2.0]);                       x1.requires_grad = True\n",
    "w1 = torch.tensor([-3.0]);                      w1.requires_grad = True\n",
    "x2 = torch.tensor([0.0]);                       x2.requires_grad = True\n",
    "w2 = torch.tensor([1.0]);                       w2.requires_grad = True\n",
    "b = torch.tensor([6.8813735870195432]);         b.requires_grad = True\n",
    "\n",
    "x1w1 = x1 * w1\n",
    "x2w2 = x2 * w2\n",
    "\n",
    "x1w1x2w2 = x1w1 + x2w2 + b\n",
    "\n",
    "out = torch.tanh(x1w1x2w2)\n",
    "\n",
    "print(f\"out = {out.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40eea925-fcdf-4718-9ed0-88671606b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b5713e-267b-45b7-b5d9-fd87b70bf0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x1.grad = {x1.grad.item()}\")\n",
    "print(f\"w1.grad = {w1.grad.item()}\")\n",
    "print(f\"x2.grad = {x2.grad.item()}\")\n",
    "print(f\"w2.grad = {w2.grad.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac1d380-2a5e-4d82-abf0-2cf274a451f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = {\n",
    "    \"x1\": x1.grad.item(),\n",
    "    \"w1\": w1.grad.item(),\n",
    "    \"x2\": x2.grad.item(),\n",
    "    \"w2\": w2.grad.item(),\n",
    "}\n",
    "# Check if the gradients are the same\n",
    "assert grads[\"x1\"] == x1.grad.item()\n",
    "assert grads[\"w1\"] == w1.grad.item()\n",
    "assert grads[\"x2\"] == x2.grad.item()\n",
    "assert grads[\"w2\"] == w2.grad.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb1722-13b3-4b2d-b5f8-4f25813463de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
