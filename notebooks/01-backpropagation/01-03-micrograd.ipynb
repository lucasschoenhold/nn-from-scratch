{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17120c50-ebc0-42d1-9d61-03453dcbc3b5",
   "metadata": {},
   "source": [
    "# Micrograd\n",
    "We're now going to codify our observations from backpropagation and will define an autograd-engine that will automatically calculating gradients based on the inputs\n",
    "\n",
    "## Backward based on operations\n",
    "- Every operation defines it's backward process based on the chain rule - ``_backward()`` function\n",
    "- The ``_backward()`` function by default does nothing, and this is true for all leaf noode (nodes after which no operation is perfomed)\n",
    "- For all other operations the ``_backward()`` function is defined as a closure, and then assigned to the attribute of ``_backward()`` of that object\n",
    "\n",
    "\n",
    "The ``_backward()`` function can now be called in the correct order on the node and fills in the gradients of the graph based on the operations.\n",
    "\n",
    "## Backward for one node\n",
    "To avoid having to manually determine the order in which the ``_backward()`` functions have to be called, we will use topological sorting to automatically determine the order and then call the function based on the order.\n",
    "\n",
    "$\\Rightarrow$ This enabled us to only having to call ``backward()`` on the individual node and it will recursivelly iterate throught the graph and call the intermediate ``_backward()``s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1572a3b7-62ec-448a-b442-5fd3f3716922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d95962-93e8-4439-8e84-97291c0e18d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Value:\n",
    "    def __init__(self, data, _children=(), _op: str = None, label: str = \"\"):\n",
    "        self.data = data\n",
    "        self.grad = 0.0\n",
    "        self._prev = set(_children)\n",
    "        self._op = _op\n",
    "        self.label = label\n",
    "        # This will perform the chain rule based on the operation\n",
    "        self._backward: callable = lambda: None\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Value(data={self.data})\"\n",
    "\n",
    "    def __add__(self, other):\n",
    "        out = Value(self.data + other.data, _children=(self, other), _op=\"+\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += 1.0 * out.grad\n",
    "            other.grad += 1.0 * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        out = Value(self.data * other.data, _children=(self, other), _op=\"*\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += other.data * out.grad\n",
    "            other.grad += self.data * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def tanh(self):\n",
    "        x = self.data\n",
    "        t = (math.exp(2 * x) - 1) / (math.exp(2 * x) + 1)\n",
    "        out = Value(t, _children=(self,), _op=\"tanh\")\n",
    "\n",
    "        def _backward():\n",
    "            self.grad += (1 - t**2) * out.grad\n",
    "\n",
    "        out._backward = _backward\n",
    "        return out\n",
    "\n",
    "    def backward(self):\n",
    "        topo = []\n",
    "        visited = set()\n",
    "\n",
    "        def build_topo(v):\n",
    "            if v not in visited:\n",
    "                visited.add(v)\n",
    "                for child in v._prev:\n",
    "                    build_topo(child)\n",
    "                topo.append(v)\n",
    "\n",
    "        build_topo(self)\n",
    "        self.grad = 1.0\n",
    "        for node in reversed(topo):  # Needs to be reversed because we start at the end\n",
    "            node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9f455-548a-4497-b74c-73083f08da6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the computation graph\n",
    "from graphviz import Digraph\n",
    "\n",
    "\n",
    "def trace(root):\n",
    "    nodes, edges = set(), set()\n",
    "\n",
    "    def build(v):\n",
    "        if v not in nodes:\n",
    "            nodes.add(v)\n",
    "            for child in v._prev:\n",
    "                edges.add((child, v))\n",
    "                build(child)\n",
    "\n",
    "    build(root)\n",
    "    return nodes, edges\n",
    "\n",
    "\n",
    "# for any value use a rectangle, for any operation use a circle\n",
    "def draw_graph(value: Value):\n",
    "    dot = Digraph(format=\"svg\", graph_attr={\"rankdir\": \"LR\"})  # Left to right\n",
    "    nodes, edges = trace(value)\n",
    "    # For each node, add a rectangle with the value\n",
    "    for n in nodes:\n",
    "        uid = str(id(n))\n",
    "        dot.node(\n",
    "            name=uid,\n",
    "            label=\"{%s | data %.4f | grad %.4f }\" % (n.label, n.data, n.grad),\n",
    "            shape=\"record\",\n",
    "        )\n",
    "        # For any operation, use a circle\n",
    "        if n._op:\n",
    "            dot.node(name=uid + n._op, label=n._op)\n",
    "            # Add edges to the graph\n",
    "            dot.edge(uid + n._op, uid)\n",
    "    for n1, n2 in edges:\n",
    "        dot.edge(str(id(n1)), str(id(n2)) + n2._op)\n",
    "    return dot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e81c267-de70-4001-b60e-cbe4de906d4e",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4693859-24c9-42e1-b278-00a2a843951d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs x1,x2\n",
    "x1 = Value(2.0, label=\"x1\")\n",
    "x2 = Value(0.0, label=\"x2\")\n",
    "# weights wl,w2\n",
    "w1 = Value(-3.0, label=\"w1\")\n",
    "w2 = Value(1.0, label=\"w2\")\n",
    "# bias of the neuron\n",
    "b = Value(6.8813735870195432, label=\"b\")  # Value set so the numbers come out \"nice\"\n",
    "# x1*w1 + x2*w2 + b\n",
    "x1w1 = x1 * w1\n",
    "x1w1.label = \"x1*w1\"\n",
    "x2w2 = x2 * w2\n",
    "x2w2.label = \"x2*w2\"\n",
    "x1w1x2w2 = x1w1 + x2w2\n",
    "x1w1x2w2.label = \"x1*w1 + x2*w2\"\n",
    "n = x1w1x2w2 + b\n",
    "n.label = \"n\"\n",
    "o = n.tanh()\n",
    "o.label = \"o\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ea216-d8fc-440e-990a-f2dccd9a7169",
   "metadata": {},
   "source": [
    "# Calling ``_backward()`` manually\n",
    "We're now going to let the ``_backward()`` function of the operations compute the gradients instead of doing it manually.\n",
    "\n",
    "For this we have to call the function in the right order beginning at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713a573c-1b12-45d3-bdad-945c782767a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78f14cb-af00-4b4d-a97f-ac0add3761a0",
   "metadata": {},
   "source": [
    "The base case is always $1$, and since ``other.grad = 0`` not setting the base case will result in an error. Therefore our gradient at the output is $1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f58c8-85d9-4e26-9534-6c8ca89590a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grad = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63721e51-c206-4b6d-8c5a-0de213581c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "o._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6273d-0dd8-4051-bc76-312e3d4add8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4199f7-8226-416c-b7fa-e0315d7af083",
   "metadata": {},
   "outputs": [],
   "source": [
    "b._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897cb0dc-379e-4b48-b086-df5f1c1ac7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1x2w2._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1534a8a7-75c2-4e80-ad04-5007fc7c78d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1w1._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00c84d6-d63f-4aae-8eba-5d355a17628e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2w2._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556be47-5a28-43d4-a9b5-53adb88705cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cfacd23-dc3a-45c9-8934-868b7f1acddc",
   "metadata": {},
   "source": [
    "# Automatically computing the full graph\n",
    "We now would like to call everything in one go. We never want to call the ``_backward()`` functions individually.\n",
    "\n",
    "To perfom a backward pass of a node we have to ensure that we call tha backward on all of it's children first, because those gradients influence the current node.\n",
    "\n",
    "-> **We have to compute everything that needs to computed before computing the current gradient!**\n",
    "\n",
    "For this the graph needs to be in a layout where all the edges flow into one direction so that the gradients can be perfomed accordingly. This can be achieved by applying **topological sort** on the graph which returns such a layout!\n",
    "\n",
    "<img src=\"../img/topological-sort.webp\" alt=\"Topological Sort Example\">\n",
    "\n",
    "This example show the original DAG (Directed acyclic graph) and it's two possible topological orderings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6241ac0a-2317-4904-9d9b-00159fed68dc",
   "metadata": {},
   "source": [
    "**How it works:**\n",
    "- We start at a root node (in our case the last node in the graph ``o``)\n",
    "- We mark the node as visited\n",
    "- We then recurively visit all it's children first and make them add themselves to the ``topo`` list\n",
    "- **We only add the current nodes after all it's children have been added**\n",
    "  - This guarentees us that all the nodes flow into one direction, and that out children will be processed first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f23946-9aae-4c33-81c3-5ceabc3fdbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo = []\n",
    "visited = set()\n",
    "\n",
    "\n",
    "def build_topo(v):\n",
    "    if v not in visited:\n",
    "        visited.add(v)\n",
    "        for child in v._prev:\n",
    "            build_topo(child)\n",
    "        topo.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd59d48-9345-43f8-b7d8-069fa4ec9a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting at the root node (output node)\n",
    "build_topo(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d7784d-bace-4978-9cba-929fa50118de",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2108f37-1f24-4dfe-9e33-b441e6f48e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.grad = 1.0\n",
    "\n",
    "for node in reversed(topo):  # Needs to be reversed because we start at the end\n",
    "    node._backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8ff927-f7a8-4987-a763-fc603d97d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34647cb-684a-493b-9524-84e2c3125862",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_graph(o)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfea2c2-8e14-41ab-a5bb-2b81b495cbb1",
   "metadata": {},
   "source": [
    "# Using variables more than once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37610ca-649c-4730-9d96-df5f8cb58a3d",
   "metadata": {},
   "source": [
    "If we're using a variable more than once such as\n",
    "```python\n",
    "a = Value(3.0, label='a')\n",
    "b = a + a; b.label='b'\n",
    "b.backward()\n",
    "draw_graph(b)\n",
    "```\n",
    "we're getting:\n",
    "\n",
    "<img src='../img/multiple-use-variable-wrong-result.svg' alt='Wrong result when using a variable multiple time'>\n",
    "\n",
    "**This result is wrong** as the gradient of $a$ has to be $2$, because it is used twice and the $+$ node distributes the gradients to it's children, so it should distribute $1$ twice because of the double usage.\n",
    "\n",
    "The reason it's not doing this is because when a variable is used more than once, what happens during the backward pass is that the ``_backward()`` is called twice, and because were setting the ``self.grad`` in the ``_backward()`` function of the operation, we override the old gradient, leading to an incorrect answer.\n",
    "\n",
    "Old implementation that reproduces the bug:\n",
    "```python\n",
    "def _backward():\n",
    "    self.grad = 1.0 * out.grad\n",
    "    other.grad = 1.0 * out.grad\n",
    "```\n",
    "\n",
    "Instead of multiple usage of a variable (which is the general idea), the gradients accumulate, meaning they add up over time. Therefore we just need to add a ``+`` in front of the equals to ensure accumulation:\n",
    "```python\n",
    "def _backward():\n",
    "    self.grad += 1.0 * out.grad\n",
    "    other.grad += 1.0 * out.grad\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f81e1e-870b-41db-aca0-07219974f327",
   "metadata": {},
   "source": [
    "This now works correctly because of the implementation above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e1ad5-0ee7-44e2-b58f-c093755758d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Value(3.0, label=\"a\")\n",
    "b = a + a\n",
    "b.label = \"b\"\n",
    "b.backward()\n",
    "draw_graph(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21866d87-6d1e-41c9-a37c-0f50fd66c71c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
